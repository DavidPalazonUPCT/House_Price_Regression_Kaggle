{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Configuracion de seaborn\n",
    "sns.set_theme(style='whitegrid', context='paper', palette='muted')\n",
    "\n",
    "# Agregar el directorio de scripts al path\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'scripts'))\n",
    "\n",
    "# Importar el logger personalizado\n",
    "from logger import CustomLogger\n",
    "\n",
    "# Inicializar el logger\n",
    "logger = CustomLogger(developer='David')\n",
    "app_logger = logger.get_logger('app')\n",
    "errors_logger = logger.get_logger('errors')\n",
    "\n",
    "try:\n",
    "    # Cargar los datos de entrenamiento\n",
    "    train_data = pd.read_csv('../data/train.csv')\n",
    "    app_logger.info(\"Conjunto de datos de entrenamiento cargado exitosamente.\")\n",
    "except FileNotFoundError:\n",
    "    errors_logger.error(\"No se pudo encontrar el archivo de datos de entrenamiento.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    errors_logger.error(f\"Error al cargar los datos de entrenamiento: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Cargamos test.csv\n",
    "try:\n",
    "    test_data = pd.read_csv('../data/test.csv')\n",
    "    app_logger.info(\"Conjunto de datos de test cargado exitosamente.\")\n",
    "except FileNotFoundError:\n",
    "    errors_logger.error(\"No se pudo encontrar el archivo de datos de test.\")\n",
    "    raise\n",
    "\n",
    "# Mostrar las primeras filas del conjunto de datos\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes por columna:\n",
      "              Total  Porcentaje\n",
      "PoolQC         1453   99.520548\n",
      "MiscFeature    1406   96.301370\n",
      "Alley          1369   93.767123\n",
      "Fence          1179   80.753425\n",
      "FireplaceQu     690   47.260274\n",
      "LotFrontage     259   17.739726\n",
      "GarageType       81    5.547945\n",
      "GarageYrBlt      81    5.547945\n",
      "GarageFinish     81    5.547945\n",
      "GarageQual       81    5.547945\n",
      "GarageCond       81    5.547945\n",
      "BsmtExposure     38    2.602740\n",
      "BsmtFinType2     38    2.602740\n",
      "BsmtFinType1     37    2.534247\n",
      "BsmtCond         37    2.534247\n",
      "BsmtQual         37    2.534247\n",
      "MasVnrArea        8    0.547945\n",
      "MasVnrType        8    0.547945\n",
      "Electrical        1    0.068493\n",
      "\n",
      "Número de filas duplicadas: 0\n"
     ]
    }
   ],
   "source": [
    "# Valores faltantes\n",
    "print(\"Valores faltantes por columna:\")\n",
    "valores_faltantes = train_data.isnull().sum()\n",
    "porcentaje_faltantes = 100 * train_data.isnull().sum() / len(train_data)\n",
    "tabla_faltantes = pd.concat([valores_faltantes, porcentaje_faltantes], axis=1, keys=['Total', 'Porcentaje'])\n",
    "print(tabla_faltantes[tabla_faltantes['Total'] > 0].sort_values('Total', ascending=False))\n",
    "\n",
    "# Filas duplicadas\n",
    "filas_duplicadas = train_data.duplicated().sum()\n",
    "print(f\"\\nNúmero de filas duplicadas: {filas_duplicadas}\")\n",
    "\n",
    "# Registrar en el log\n",
    "if valores_faltantes.sum() > 0:\n",
    "    app_logger.info(f\"Se encontraron {valores_faltantes.sum()} valores faltantes en total.\")\n",
    "else:\n",
    "    app_logger.info(\"No se encontraron valores faltantes en el conjunto de datos.\")\n",
    "\n",
    "if filas_duplicadas > 0:\n",
    "    app_logger.warning(f\"Se encontraron {filas_duplicadas} filas duplicadas en el conjunto de datos.\")\n",
    "else:\n",
    "    app_logger.info(\"No se encontraron filas duplicadas en el conjunto de datos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes por columna en el conjunto de test:\n",
      "              Total  Porcentaje\n",
      "PoolQC         1456   99.794380\n",
      "MiscFeature    1408   96.504455\n",
      "Alley          1352   92.666210\n",
      "Fence          1169   80.123372\n",
      "FireplaceQu     730   50.034270\n",
      "LotFrontage     227   15.558602\n",
      "GarageCond       78    5.346127\n",
      "GarageYrBlt      78    5.346127\n",
      "GarageQual       78    5.346127\n",
      "GarageFinish     78    5.346127\n",
      "GarageType       76    5.209047\n",
      "BsmtCond         45    3.084304\n",
      "BsmtExposure     44    3.015764\n",
      "BsmtQual         44    3.015764\n",
      "BsmtFinType1     42    2.878684\n",
      "BsmtFinType2     42    2.878684\n",
      "MasVnrType       16    1.096642\n",
      "MasVnrArea       15    1.028101\n",
      "MSZoning          4    0.274160\n",
      "BsmtFullBath      2    0.137080\n",
      "BsmtHalfBath      2    0.137080\n",
      "Functional        2    0.137080\n",
      "Utilities         2    0.137080\n",
      "GarageCars        1    0.068540\n",
      "GarageArea        1    0.068540\n",
      "TotalBsmtSF       1    0.068540\n",
      "KitchenQual       1    0.068540\n",
      "BsmtUnfSF         1    0.068540\n",
      "BsmtFinSF2        1    0.068540\n",
      "BsmtFinSF1        1    0.068540\n",
      "Exterior2nd       1    0.068540\n",
      "Exterior1st       1    0.068540\n",
      "SaleType          1    0.068540\n",
      "\n",
      "Número de filas duplicadas en el conjunto de test: 0\n"
     ]
    }
   ],
   "source": [
    "# Valores faltantes en el conjunto de test\n",
    "print(\"Valores faltantes por columna en el conjunto de test:\")\n",
    "valores_faltantes_test = test_data.isnull().sum()\n",
    "porcentaje_faltantes_test = 100 * test_data.isnull().sum() / len(test_data)\n",
    "tabla_faltantes_test = pd.concat([valores_faltantes_test, porcentaje_faltantes_test], axis=1, keys=['Total', 'Porcentaje'])\n",
    "print(tabla_faltantes_test[tabla_faltantes_test['Total'] > 0].sort_values('Total', ascending=False))\n",
    "\n",
    "# Filas duplicadas en el conjunto de test\n",
    "filas_duplicadas_test = test_data.duplicated().sum()\n",
    "print(f\"\\nNúmero de filas duplicadas en el conjunto de test: {filas_duplicadas_test}\")\n",
    "\n",
    "# Registrar en el log para el conjunto de test\n",
    "if valores_faltantes_test.sum() > 0:\n",
    "    app_logger.info(f\"Se encontraron {valores_faltantes_test.sum()} valores faltantes en total en el conjunto de test.\")\n",
    "else:\n",
    "    app_logger.info(\"No se encontraron valores faltantes en el conjunto de test.\")\n",
    "\n",
    "if filas_duplicadas_test > 0:\n",
    "    app_logger.warning(f\"Se encontraron {filas_duplicadas_test} filas duplicadas en el conjunto de test.\")\n",
    "else:\n",
    "    app_logger.info(\"No se encontraron filas duplicadas en el conjunto de test.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Columns on Train\n",
    "- Pool Quality Col has 99,52% missing values, but we still have Pool Area wich i think is more important than PoolQc\n",
    "- MiscFeature Col has 96.30% missing values. We also have MiscVal that represents the value of Misc Feature.\n",
    "    - Each Misc Feature has a unique value or has multiple values?? If each MiscFeature has only one unique value (univoque relationship) we can drop MiscFeature and leave Misc Val because we wont lose info, otherwise, drop both. Even if MiscVal has no NaNs, using it on its own may not be the best for the model to gather relationships.\n",
    "- Alley has 93% missing values, no other col is related to this one so we can directly drop it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar si la relación es unívoca entre MiscFeature y MiscVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relación entre MiscFeature y MiscVal:\n",
      "  MiscFeature  Valores_Unicos_MiscVal\n",
      "0        Gar2                       2\n",
      "1        Othr                       2\n",
      "2        Shed                      18\n",
      "3        TenC                       1\n",
      "\n",
      "La relación entre MiscFeature y MiscVal no es unívoca.\n",
      "\n",
      "Ejemplos de MiscFeature con múltiples valores de MiscVal:\n",
      "MiscFeature: Gar2\n",
      "Valores de MiscVal: [15500  8300]\n",
      "\n",
      "MiscFeature: Othr\n",
      "Valores de MiscVal: [3500    0]\n",
      "\n",
      "MiscFeature: Shed\n",
      "Valores de MiscVal: [ 700  350  500  400  480  450 1200  800 2000  600 1300   54  620  560\n",
      " 1400    0 1150 2500]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame con MiscFeature y MiscVal\n",
    "misc_df = train_data[['MiscFeature', 'MiscVal']]\n",
    "\n",
    "# Agrupar por MiscFeature y contar los valores únicos de MiscVal\n",
    "relacion_misc = misc_df.groupby('MiscFeature')['MiscVal'].nunique().reset_index()\n",
    "relacion_misc.columns = ['MiscFeature', 'Valores_Unicos_MiscVal']\n",
    "\n",
    "print(\"Relación entre MiscFeature y MiscVal:\")\n",
    "print(relacion_misc)\n",
    "\n",
    "# Verificar si cada MiscFeature tiene un único valor de MiscVal\n",
    "es_univoca = (relacion_misc['Valores_Unicos_MiscVal'] == 1).all()\n",
    "\n",
    "if es_univoca:\n",
    "    print(\"\\nLa relación entre MiscFeature y MiscVal es unívoca.\")\n",
    "    app_logger.info(\"La relación entre MiscFeature y MiscVal es unívoca. Se puede considerar dejar una columna.\")\n",
    "else:\n",
    "    print(\"\\nLa relación entre MiscFeature y MiscVal no es unívoca.\")\n",
    "    app_logger.info(\"La relación entre MiscFeature y MiscVal no es unívoca. Se recomienda eliminar ambas columnas.\")\n",
    "\n",
    "# Mostrar ejemplos de MiscFeature con múltiples valores de MiscVal\n",
    "if not es_univoca:\n",
    "    print(\"\\nEjemplos de MiscFeature con múltiples valores de MiscVal:\")\n",
    "    ejemplos_multiples = relacion_misc[relacion_misc['Valores_Unicos_MiscVal'] > 1]\n",
    "    for _, row in ejemplos_multiples.iterrows():\n",
    "        feature = row['MiscFeature']\n",
    "        valores = misc_df[misc_df['MiscFeature'] == feature]['MiscVal'].unique()\n",
    "        print(f\"MiscFeature: {feature}\")\n",
    "        print(f\"Valores de MiscVal: {valores}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que MiscVal y MiscFeature no son univocamente relacionados, se eliminan ambas columnas puesto que estan relacionadas y no se tienen datos de una y la otra son casi todo 0\n",
    "train_data = train_data.drop(columns=['MiscFeature', 'MiscVal'])\n",
    "test_data = test_data.drop(columns=['MiscFeature', 'MiscVal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas eliminadas: Alley, PoolQC\n",
      "\n",
      "Forma del conjunto de datos original: (1460, 79)\n",
      "Forma del conjunto de datos filtrado: (1460, 77)\n"
     ]
    }
   ],
   "source": [
    "# Filtrar columnas con más del 90% de valores faltantes\n",
    "umbral_faltantes = 0.9\n",
    "columnas_a_eliminar = tabla_faltantes[tabla_faltantes['Porcentaje'] > 90].index\n",
    "train_data_filtrado = train_data.drop(columns=columnas_a_eliminar.drop(['MiscFeature']))\n",
    "\n",
    "# Registrar en el log\n",
    "if len(columnas_a_eliminar) > 0:\n",
    "    app_logger.info(f\"Se eliminaron {len(columnas_a_eliminar)} columnas con más del 90% de valores faltantes: {', '.join(columnas_a_eliminar)}\")\n",
    "    print(f\"Columnas eliminadas: {', '.join(columnas_a_eliminar.drop(['MiscFeature']))}\")\n",
    "else:\n",
    "    app_logger.info(\"No se encontraron columnas con más del 90% de valores faltantes.\")\n",
    "    print(\"No se encontraron columnas con más del 90% de valores faltantes.\")\n",
    "\n",
    "# Mostrar la forma del nuevo conjunto de datos\n",
    "print(f\"\\nForma del conjunto de datos original: {train_data.shape}\")\n",
    "print(f\"Forma del conjunto de datos filtrado: {train_data_filtrado.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\envs\\david_pcc\\lib\\site-packages\\dtale\\views.py:798: FutureWarning:\n",
      "\n",
      "['MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'Fence'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "\n",
      "2024-07-22 03:26:26,627 - INFO     - Se ha generado un análisis interactivo utilizando dtale.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha generado un análisis interactivo con dtale.\n",
      "Por favor, acceda a la siguiente URL para explorar los datos: http://PortatilDavid:40000\n"
     ]
    }
   ],
   "source": [
    "# Importar dtale\n",
    "import dtale\n",
    "\n",
    "# Crear una instancia de dtale con los datos filtrados\n",
    "d = dtale.show(train_data_filtrado)\n",
    "\n",
    "# Mostrar el enlace para acceder a la interfaz de dtale\n",
    "print(\"Se ha generado un análisis interactivo con dtale.\")\n",
    "print(f\"Por favor, acceda a la siguiente URL para explorar los datos: {d._url}\")\n",
    "\n",
    "# Registrar en el log\n",
    "app_logger.info(\"Se ha generado un análisis interactivo utilizando dtale.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis D-Tale\n",
    "- We found important predictive power with the following features ``FullBath_quantile, FullBath, GrLiveArea, GrLiveArea_power, GrLiveArea_quantile,GrLiveArea_robust, GarageCars, OverallQual``\n",
    "- Maybe add a feature that stratifies if the house has garage or not (Never Mind ``GarageCond`` and ``GarageQual`` already do).\n",
    "- 81 houses have 0 car capacity in garage and 0 sqft but not NA specified on ``GarageCond``, ``GarageQual``, ``GarageType`` and ``GarageFinish``, drop rows with 0 or impute them. If a house has 0 for ``GarageCars`` and ``GarageArea``, the ``GarageType``, ``GarageCond``, ``GarageQual``, and ``GarageFinish`` should be NA?.\n",
    "- ``GarageQual`` and ``GarageCond`` are duplicates.\n",
    "- The features ``Fireplaces`` and ``FireplaceQu`` are both NaN or 0 for the same row, so imputation should be done simultaneosly maintaining their possible relationship, imputing the mean and most frecuent values independently could potentially introduce noise as the pairing could possibly be random.\n",
    "\n",
    "- Most of the numerical variables where Non-normal, with log relationship with sales price (target).\n",
    "\n",
    "    ### Low Variance Features\n",
    "    - Dtale showed the following features having low variance:\n",
    "        - ``BsmtFinSF2`` : 88.56% are 0s, related to this feature we have ``BsmtFinType2`` with 88.33% of rows with value 'Unf' which means 'unfinished '. This could mean that as it is unfinshed the sqft on ``BsmtFinSF2`` are not taken into account so the value will be 0?. Coincidence percentaje between ``BsmtFinType2 == 'Unf' and BsmtFinSF2 == 0``: 97.14%\n",
    "        - ``LowQualFinSF``: 98.22% are 0s. This feature represents 'Low quality finished square feet (all floors)', i dont really know if we could impute this values as the meaning of the variable is not deterministic or easy to define because it represent the sqft of LowQuality finished sqft of all floors, but there isnt a feature defining wich houses are LowQuality or finished. \n",
    "            - Maybe we could create a feature called ``Total_sqft`` and/or Mean between all floors per house, etc... \n",
    "        - ``KitchenAbvGr``: From possible values {0,1,2,3} 95.34% are 1s. These feature represents the number of kitchens above grade. There is also the ``TotRmsAbvGrd`` feature measuring the total rooms above grade and the feature ``KitchenQual`` wich indicates the quality of the kitchens. Due to this i think we could drop this feature and leave the other two, as the model will probably discover the relationships.\n",
    "        - ``PoolArea``: 99.52% values are 0s. The related feature was ``PoolQC`` representing the pool quality but it had 99.79% of NaNs values so i think we can drop both.\n",
    "        - ``EnclosedPorch``: 85.75% of 0s.\n",
    "        - ``3SsnPorch``: 98.36% of 0s.\n",
    "        - ``ScreenPorch``: 92.05% of 0s.\n",
    "        - Out of this 3 features realted with sqft of different types of Porch the one that has the most sens on maintaining on the dataset is ``EnclosedPorch`` that is de opposite to ``OpenPorch`` (that measures the open porch sqft) and its not that much full of 0s as the other two. This could be okay with te model as it can learn that if we have some value on ``EnclosedPorch``, the house has an enclosed porch, and the same for ``OpenPorch``. The other 2 features are practically all 0s and not much value can be obtained. I think the 2 important features are the ones i mentioned, we could do some new features to encode this info of having 1 porch or another or both.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 03:26:26,689 - INFO     - Se identificaron 696 casas remodeladas y 764 casas no remodeladas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de casas remodeladas: 696\n",
      "Número de casas no remodeladas: 764\n",
      "Porcentaje de casas remodeladas: 47.67%\n"
     ]
    }
   ],
   "source": [
    "# Comparar YearRemodAdd con YearBuilt para identificar casas remodeladas\n",
    "casas_remodeladas = train_data_filtrado[train_data_filtrado['YearRemodAdd'] != train_data_filtrado['YearBuilt']]\n",
    "casas_no_remodeladas = train_data_filtrado[train_data_filtrado['YearRemodAdd'] == train_data_filtrado['YearBuilt']]\n",
    "\n",
    "# Calcular el número de casas remodeladas y no remodeladas\n",
    "num_remodeladas = len(casas_remodeladas)\n",
    "num_no_remodeladas = len(casas_no_remodeladas)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Número de casas remodeladas: {num_remodeladas}\")\n",
    "print(f\"Número de casas no remodeladas: {num_no_remodeladas}\")\n",
    "print(f\"Porcentaje de casas remodeladas: {(num_remodeladas / len(train_data_filtrado)) * 100:.2f}%\")\n",
    "\n",
    "# Registrar en el log\n",
    "app_logger.info(f\"Se identificaron {num_remodeladas} casas remodeladas y {num_no_remodeladas} casas no remodeladas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 03:26:26,721 - INFO     - El 9.45% del total de casas tienen GarageYrBlt a más de 10 años de YearBuilt y YearRemodAdd.\n",
      "2024-07-22 03:26:26,722 - INFO     - El 21.71% de las casas tienen GarageYrBlt que no coincide ni con YearBuilt ni con YearRemodAdd.\n",
      "2024-07-22 03:26:26,723 - INFO     - Porcentaje de casas donde GarageYrBlt está a menos de 10 años de YearBuilt: 22.08%\n",
      "2024-07-22 03:26:26,723 - INFO     - Porcentaje de casas donde GarageYrBlt está a menos de 10 años de YearRemodAdd: 23.03%\n",
      "2024-07-22 03:26:26,724 - INFO     - Porcentaje de casas donde GarageYrBlt está a más de 10 años de ambas fechas: 43.53%\n",
      "2024-07-22 03:26:26,727 - INFO     - Análisis de YearBuilt vs GarageYrBlt completado. Coinciden: 74.59%, Diferentes: 25.41%\n",
      "2024-07-22 03:26:26,727 - INFO     - Para casas con garage sin terminar, tiempo medio entre construcción: 5.55 años, tiempo medio hasta remodelación: 6.93 años\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de casas donde YearBuilt coincide con GarageYrBlt: 74.59%\n",
      "Del 25.41% que no coincide con YearBuilt, 14.56% coincide con YearRemodAdd\n",
      "Porcentaje de casas donde YearBuilt es diferente de GarageYrBlt: 25.41%\n",
      "Porcentaje de casas donde GarageYrBlt no coincide ni con YearBuilt ni con YearRemodAdd: 21.71%\n",
      "Porcentaje de casas donde GarageYrBlt está a más de 10 años de YearBuilt y YearRemodAdd respecto al total: 9.45%\n",
      "Porcentaje de casas donde GarageYrBlt no coincide con YearBuilt ni con YearRemodAdd y está a menos de 10 años de YearBuilt: 22.08%\n",
      "Porcentaje de casas donde GarageYrBlt no coincide con YearBuilt ni con YearRemodAdd y está a menos de 10 años de YearRemodAdd: 23.03%\n",
      "Porcentaje de casas donde GarageYrBlt no coincide con YearBuilt ni con YearRemodAdd y está a más de 10 años de ambas fechas: 43.53%\n",
      "Tiempo medio entre GarageYrBlt y YearBuilt: 5.55 años\n",
      "Tiempo medio entre GarageYrBlt y YearRemodAdd: 6.93 años\n",
      "Tiempo mínimo entre GarageYrBlt y YearBuilt: -10.00 años\n",
      "Tiempo máximo entre GarageYrBlt y YearBuilt: 123.00 años\n",
      "Tiempo mínimo entre GarageYrBlt y YearRemodAdd: -53.00 años\n",
      "Tiempo máximo entre GarageYrBlt y YearRemodAdd: 98.00 años\n",
      "Tiempo medio entre YearBuilt y YearRemodAdd: 13.60 años\n",
      "Tiempo mínimo entre YearBuilt y YearRemodAdd: 0.00 años\n",
      "Tiempo máximo entre YearBuilt y YearRemodAdd: 123.00 años\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Comparar YearBuilt con GarageYrBlt\n",
    "coinciden = train_data_filtrado['YearBuilt'] == train_data_filtrado['GarageYrBlt']\n",
    "diferentes = train_data_filtrado['YearBuilt'] != train_data_filtrado['GarageYrBlt']\n",
    "\n",
    "# Calcular porcentajes\n",
    "porcentaje_coinciden = (coinciden.sum() / len(train_data_filtrado)) * 100\n",
    "porcentaje_diferentes = (diferentes.sum() / len(train_data_filtrado)) * 100\n",
    "\n",
    "print(f\"Porcentaje de casas donde YearBuilt coincide con GarageYrBlt: {porcentaje_coinciden:.2f}%\")\n",
    "\n",
    "# Analizar cuántas de las que no coinciden con YearBuilt coinciden con YearRemodAdd\n",
    "coinciden_con_remod = train_data_filtrado[diferentes]['GarageYrBlt'] == train_data_filtrado[diferentes]['YearRemodAdd']\n",
    "porcentaje_coinciden_remod = (coinciden_con_remod.sum() / diferentes.sum()) * 100\n",
    "\n",
    "print(f\"Del {porcentaje_diferentes:.2f}% que no coincide con YearBuilt, {porcentaje_coinciden_remod:.2f}% coincide con YearRemodAdd\")\n",
    "print(f\"Porcentaje de casas donde YearBuilt es diferente de GarageYrBlt: {porcentaje_diferentes:.2f}%\")\n",
    "\n",
    "# Calcular el porcentaje que no coincide ni con YearBuilt ni con YearRemodAdd\n",
    "no_coincide_ninguno = (~coinciden) & (~coinciden_con_remod)\n",
    "porcentaje_no_coincide_ninguno = (no_coincide_ninguno.sum() / len(train_data_filtrado)) * 100\n",
    "\n",
    "print(f\"Porcentaje de casas donde GarageYrBlt no coincide ni con YearBuilt ni con YearRemodAdd: {porcentaje_no_coincide_ninguno:.2f}%\")\n",
    "\n",
    "# Evaluar la proximidad de GarageYrBlt con YearBuilt y YearRemodAdd de las que no coinciden con YearBuilt ni con YearRemodAdd\n",
    "no_coincide_ninguno = train_data_filtrado[no_coincide_ninguno].copy()\n",
    "no_coincide_ninguno['diff_with_yearbuilt'] = abs(no_coincide_ninguno['GarageYrBlt'] - no_coincide_ninguno['YearBuilt'])\n",
    "no_coincide_ninguno['diff_with_yearremodadd'] = abs(no_coincide_ninguno['GarageYrBlt'] - no_coincide_ninguno['YearRemodAdd'])\n",
    "\n",
    "# Determinar proximidad dentro de 10 años\n",
    "proxima_a_yearbuilt = no_coincide_ninguno[no_coincide_ninguno['diff_with_yearbuilt'] <= 7]\n",
    "proxima_a_yearremodadd = no_coincide_ninguno[no_coincide_ninguno['diff_with_yearremodadd'] <= 7]\n",
    "mas_de_10_anos = no_coincide_ninguno[(no_coincide_ninguno['diff_with_yearbuilt'] > 7) & (no_coincide_ninguno['diff_with_yearremodadd'] > 7)]\n",
    "\n",
    "# Calcular porcentajes\n",
    "porcentaje_proxima_a_yearbuilt = (len(proxima_a_yearbuilt) / len(no_coincide_ninguno)) * 100\n",
    "porcentaje_proxima_a_yearremodadd = (len(proxima_a_yearremodadd) / len(no_coincide_ninguno)) * 100\n",
    "porcentaje_mas_de_10_anos = (len(mas_de_10_anos) / len(no_coincide_ninguno)) * 100\n",
    "# Calcular el porcentaje que representan las casas con más de 10 años de diferencia respecto al total\n",
    "porcentaje_mas_10_anos_total = (len(mas_de_10_anos) / len(train_data_filtrado)) * 100\n",
    "\n",
    "print(f\"Porcentaje de casas donde GarageYrBlt está a más de 10 años de YearBuilt y YearRemodAdd respecto al total: {porcentaje_mas_10_anos_total:.2f}%\")\n",
    "\n",
    "# Registrar en el log\n",
    "app_logger.info(f\"El {porcentaje_mas_10_anos_total:.2f}% del total de casas tienen GarageYrBlt a más de 10 años de YearBuilt y YearRemodAdd.\")\n",
    "\n",
    "print(f\"Porcentaje de casas donde GarageYrBlt no coincide con YearBuilt ni con YearRemodAdd y está a menos de 10 años de YearBuilt: {porcentaje_proxima_a_yearbuilt:.2f}%\")\n",
    "print(f\"Porcentaje de casas donde GarageYrBlt no coincide con YearBuilt ni con YearRemodAdd y está a menos de 10 años de YearRemodAdd: {porcentaje_proxima_a_yearremodadd:.2f}%\")\n",
    "print(f\"Porcentaje de casas donde GarageYrBlt no coincide con YearBuilt ni con YearRemodAdd y está a más de 10 años de ambas fechas: {porcentaje_mas_de_10_anos:.2f}%\")\n",
    "\n",
    "# Registrar en el log\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "app_logger = logging.getLogger(__name__)\n",
    "\n",
    "app_logger.info(f\"El {porcentaje_no_coincide_ninguno:.2f}% de las casas tienen GarageYrBlt que no coincide ni con YearBuilt ni con YearRemodAdd.\")\n",
    "app_logger.info(f\"Porcentaje de casas donde GarageYrBlt está a menos de 10 años de YearBuilt: {porcentaje_proxima_a_yearbuilt:.2f}%\")\n",
    "app_logger.info(f\"Porcentaje de casas donde GarageYrBlt está a menos de 10 años de YearRemodAdd: {porcentaje_proxima_a_yearremodadd:.2f}%\")\n",
    "app_logger.info(f\"Porcentaje de casas donde GarageYrBlt está a más de 10 años de ambas fechas: {porcentaje_mas_de_10_anos:.2f}%\")\n",
    "\n",
    "# Calcular tiempos medios y extremos\n",
    "tiempo_medio_construccion = (train_data_filtrado['GarageYrBlt'] - train_data_filtrado['YearBuilt']).mean()\n",
    "tiempo_minimo_construccion = (train_data_filtrado['GarageYrBlt'] - train_data_filtrado['YearBuilt']).min()\n",
    "tiempo_maximo_construccion = (train_data_filtrado['GarageYrBlt'] - train_data_filtrado['YearBuilt']).max()\n",
    "\n",
    "tiempo_medio_remodelacion = (train_data_filtrado['YearRemodAdd'] - train_data_filtrado['GarageYrBlt']).mean()\n",
    "tiempo_minimo_remodelacion = (train_data_filtrado['YearRemodAdd'] - train_data_filtrado['GarageYrBlt']).min()\n",
    "tiempo_maximo_remodelacion = (train_data_filtrado['YearRemodAdd'] - train_data_filtrado['GarageYrBlt']).max()\n",
    "\n",
    "tiempo_medio_hasta_remodelacion = (train_data_filtrado['YearRemodAdd'] - train_data_filtrado['YearBuilt']).mean()\n",
    "tiempo_minimo_hasta_remodelacion = (train_data_filtrado['YearRemodAdd'] - train_data_filtrado['YearBuilt']).min()\n",
    "tiempo_maximo_hasta_remodelacion = (train_data_filtrado['YearRemodAdd'] - train_data_filtrado['YearBuilt']).max()\n",
    "\n",
    "print(f\"Tiempo medio entre GarageYrBlt y YearBuilt: {tiempo_medio_construccion:.2f} años\")\n",
    "print(f\"Tiempo medio entre GarageYrBlt y YearRemodAdd: {tiempo_medio_remodelacion:.2f} años\")\n",
    "print(f\"Tiempo mínimo entre GarageYrBlt y YearBuilt: {tiempo_minimo_construccion:.2f} años\")\n",
    "print(f\"Tiempo máximo entre GarageYrBlt y YearBuilt: {tiempo_maximo_construccion:.2f} años\")\n",
    "print(f\"Tiempo mínimo entre GarageYrBlt y YearRemodAdd: {tiempo_minimo_remodelacion:.2f} años\")\n",
    "print(f\"Tiempo máximo entre GarageYrBlt y YearRemodAdd: {tiempo_maximo_remodelacion:.2f} años\")\n",
    "print(f\"Tiempo medio entre YearBuilt y YearRemodAdd: {tiempo_medio_hasta_remodelacion:.2f} años\")\n",
    "print(f\"Tiempo mínimo entre YearBuilt y YearRemodAdd: {tiempo_minimo_hasta_remodelacion:.2f} años\")\n",
    "print(f\"Tiempo máximo entre YearBuilt y YearRemodAdd: {tiempo_maximo_hasta_remodelacion:.2f} años\")\n",
    "\n",
    "# Registrar en el log\n",
    "app_logger.info(f\"Análisis de YearBuilt vs GarageYrBlt completado. \"\n",
    "                f\"Coinciden: {porcentaje_coinciden:.2f}%, Diferentes: {porcentaje_diferentes:.2f}%\")\n",
    "app_logger.info(f\"Para casas con garage sin terminar, tiempo medio entre construcción: \"\n",
    "                f\"{tiempo_medio_construccion:.2f} años, tiempo medio hasta remodelación: \"\n",
    "                f\"{tiempo_medio_remodelacion:.2f} años\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 03:26:26,750 - INFO     - El 97.14% de los casos tienen BsmtFinType2 == 'Unf' y BsmtFinSF2 == 0 simultáneamente.\n",
      "2024-07-22 03:26:26,752 - INFO     - El 0.00% de los casos tienen BsmtFinType2 == 'Unf' pero BsmtFinSF2 != 0.\n",
      "2024-07-22 03:26:26,755 - INFO     - Análisis de combinaciones con BsmtFinSF2 == 0:\n",
      "2024-07-22 03:26:26,756 - INFO     - BsmtFinType2 = 'Unf': 86.03% de los casos\n",
      "2024-07-22 03:26:26,757 - INFO     - El 88.56% de los casos tienen BsmtFinSF2 == 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de coincidencia entre BsmtFinType2 == 'Unf' y BsmtFinSF2 == 0: 97.14%\n",
      "Porcentaje de casos donde BsmtFinType2 == 'Unf' pero BsmtFinSF2 != 0: 0.00%\n",
      "Combinaciones con BsmtFinSF2 == 0:\n",
      "BsmtFinType2 = 'Unf': 1256 casos (86.03%)\n",
      "\n",
      "Porcentaje total de casos con BsmtFinSF2 == 0: 88.56%\n"
     ]
    }
   ],
   "source": [
    "# Calcular el porcentaje de coincidencia entre BsmtFinType2 == 'Unf' y BsmtFinSF2 == 0\n",
    "coincidencias = ((train_data_filtrado['BsmtFinType2'] == 'Unf') & (train_data_filtrado['BsmtFinSF2'] == 0)).sum()\n",
    "total_casos_0 = (train_data_filtrado['BsmtFinSF2']==0).sum()\n",
    "porcentaje_coincidencia = (coincidencias / total_casos_0) * 100\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(f\"Porcentaje de coincidencia entre BsmtFinType2 == 'Unf' y BsmtFinSF2 == 0: {porcentaje_coincidencia:.2f}%\")\n",
    "\n",
    "# Registrar en el log\n",
    "app_logger.info(f\"El {porcentaje_coincidencia:.2f}% de los casos tienen BsmtFinType2 == 'Unf' y BsmtFinSF2 == 0 simultáneamente.\")\n",
    "\n",
    "# Calcular casos donde no coinciden\n",
    "no_coincidencias = ((train_data_filtrado['BsmtFinType2'] == 'Unf') & (train_data_filtrado['BsmtFinSF2'] != 0)).sum()\n",
    "total_casos_no_0 = len(train_data_filtrado['BsmtFinSF2']!=0)\n",
    "porcentaje_no_coincidencia = (no_coincidencias / total_casos_no_0) * 100\n",
    "\n",
    "print(f\"Porcentaje de casos donde BsmtFinType2 == 'Unf' pero BsmtFinSF2 != 0: {porcentaje_no_coincidencia:.2f}%\")\n",
    "app_logger.info(f\"El {porcentaje_no_coincidencia:.2f}% de los casos tienen BsmtFinType2 == 'Unf' pero BsmtFinSF2 != 0.\")\n",
    "\n",
    "# Analizar las combinaciones con BsmtFinSF2 == 0\n",
    "combinaciones_cero = train_data_filtrado[train_data_filtrado['BsmtFinSF2'] == 0]['BsmtFinType2'].value_counts()\n",
    "porcentaje_combinaciones = (combinaciones_cero / len(train_data_filtrado)) * 100\n",
    "\n",
    "print(\"Combinaciones con BsmtFinSF2 == 0:\")\n",
    "for tipo, conteo in combinaciones_cero.items():\n",
    "    porcentaje = porcentaje_combinaciones[tipo]\n",
    "    print(f\"BsmtFinType2 = '{tipo}': {conteo} casos ({porcentaje:.2f}%)\")\n",
    "\n",
    "# Registrar en el log\n",
    "app_logger.info(\"Análisis de combinaciones con BsmtFinSF2 == 0:\")\n",
    "for tipo, porcentaje in porcentaje_combinaciones.items():\n",
    "    app_logger.info(f\"BsmtFinType2 = '{tipo}': {porcentaje:.2f}% de los casos\")\n",
    "\n",
    "# Calcular el porcentaje total de casos con BsmtFinSF2 == 0\n",
    "porcentaje_total_cero = (train_data_filtrado['BsmtFinSF2'] == 0).mean() * 100\n",
    "print(f\"\\nPorcentaje total de casos con BsmtFinSF2 == 0: {porcentaje_total_cero:.2f}%\")\n",
    "app_logger.info(f\"El {porcentaje_total_cero:.2f}% de los casos tienen BsmtFinSF2 == 0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XiCorr Coeficiente\n",
    "El coeficiente Xicorr (Xi-correlation coefficient) es una medida de asociación entre dos variables que puede ser utilizada como alternativa al coeficiente de correlación de Pearson, especialmente cuando las variables no tienen una relación lineal.\n",
    "\n",
    "### Definición del Coeficiente Xicorr\n",
    "\n",
    "El coeficiente Xicorr se basa en la idea de las \"permutaciones locales\". Se enfoca en la desviación de las permutaciones locales de una relación ideal, y puede ser más robusto frente a distribuciones no normales y relaciones no lineales.\n",
    "\n",
    "#### 1. Supongamos que tenemos dos variables $X$ e $Y$ con $n$ observaciones cada una.\n",
    "\n",
    "$$ X = (X_1, X_2, \\ldots, X_n) $$\n",
    "$$ Y = (Y_1, Y_2, \\ldots, Y_n) $$\n",
    "\n",
    "\n",
    "#### 2. Ordenamos ambas variables en orden ascendente.\n",
    "\n",
    "$$ X_{(1)}, X_{(2)}, \\ldots, X_{(n)} $$\n",
    "$$ Y_{(1)}, Y_{(2)}, \\ldots, Y_{(n)} $$\n",
    "\n",
    "#### 3. Calculamos las posiciones de los valores originales en los vectores ordenados. Denotamos las posiciones de $X_i$ en $X_{(i)}$ como $P_X(i)$ y de $Y_i$ en $Y_{(i)}$ como $P_Y(i)$.\n",
    "\n",
    "$$ P_X(i) = \\text{posición de } X_i \\text{ en } X_{(i)} $$\n",
    "$$ P_Y(i) = \\text{posición de } Y_i \\text{ en } Y_{(i)} $$\n",
    "\n",
    "#### 4. Definimos las permutaciones locales $ \\pi_X $ y $ \\pi_Y $ de $X$ e $Y$ respectivamente, que representan cómo se permutan los valores cuando se ordenan.\n",
    "\n",
    "#### 5. Calculamos la desviación de estas permutaciones locales de una relación ideal. Esta desviación se mide a través de una función de distancia. Una forma común de definir esta distancia es usar la distancia de Kendall ($ \\tau $).\n",
    "\n",
    "$$ \\tau(\\pi_X, \\pi_Y) = \\text{Número de discordancias entre } \\pi_X \\text{ y } \\pi_Y $$\n",
    "\n",
    "#### 6. Normalizamos esta distancia para obtener el coeficiente Xicorr. La normalización se hace para que el coeficiente esté en el rango [-1, 1], similar a los coeficientes de correlación tradicionales.\n",
    "\n",
    "$$ \\text{Xicorr}(X, Y) = 1 - \\frac{2 \\tau(\\pi_X, \\pi_Y)}{n(n-1)/2} $$\n",
    "\n",
    "Aquí, $ n(n-1)/2 $ es el número total de pares posibles en el conjunto de datos.\n",
    "\n",
    "### Interpretación del Coeficiente Xicorr\n",
    "\n",
    "- **Xicorr = 1**: Indica una correlación perfecta y positiva entre las variables $X$ e $Y$.\n",
    "- **Xicorr = -1**: Indica una correlación perfecta y negativa entre las variables $X$ e $Y$.\n",
    "- **Xicorr = 0**: Indica que no hay correlación entre las variables $X$ e $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasos Intuitivos del Cálculo del Coeficiente Xicorr\n",
    "\n",
    "1. **Ordenación de las Variables**:\n",
    "   - Imagina que tienes dos listas de números, una para cada variable, \\(X\\) e \\(Y\\). Primero, ordenas cada lista de menor a mayor.\n",
    "   - Por ejemplo, si \\(X = [4, 1, 3]\\), lo ordenas como \\(X_{ordenado} = [1, 3, 4]\\). Lo mismo haces con \\(Y\\).\n",
    "\n",
    "2. **Rastreo de las Posiciones Originales**:\n",
    "   - Luego, haces un seguimiento de las posiciones originales de los elementos en las listas ordenadas. Es decir, determinas dónde estaba originalmente cada valor en la lista desordenada.\n",
    "   - Por ejemplo, si \\(X = [4, 1, 3]\\) y \\(X_{ordenado} = [1, 3, 4]\\), el valor 1 estaba en la posición 2 originalmente, el 3 en la posición 3 y el 4 en la posición 1.\n",
    "\n",
    "3. **Comparación de las Permutaciones**:\n",
    "   - Ahora, haces lo mismo para la variable \\(Y\\). Una vez que tienes las posiciones originales de ambos conjuntos de datos ordenados, puedes compararlas.\n",
    "   - Imagina que tienes las posiciones originales de \\(X\\) como \\(\\pi_X\\) y las posiciones originales de \\(Y\\) como \\(\\pi_Y\\).\n",
    "\n",
    "4. **Medición de la Discordancia**:\n",
    "   - Comparas estas permutaciones (\\(\\pi_X\\) y \\(\\pi_Y\\)) para ver cuán diferentes son. La discordancia se mide contando cuántas veces un par de elementos está en un orden diferente en \\(X\\) en comparación con \\(Y\\).\n",
    "   - Por ejemplo, si en \\(X\\) el segundo elemento viene antes que el primero pero en \\(Y\\) el primero viene antes que el segundo, eso es una discordancia.\n",
    "\n",
    "5. **Calculo de la Distancia de Discordancia**:\n",
    "   - La distancia de Kendall (\\(\\tau\\)) es una forma común de medir esta discordancia, contando cuántas discordancias hay entre las posiciones de \\(X\\) e \\(Y\\).\n",
    "   - Si hay muchas discordancias, significa que las listas están muy desalineadas.\n",
    "\n",
    "6. **Normalización de la Distancia**:\n",
    "   - Para obtener el coeficiente Xicorr, normalizas la cantidad de discordancias para que el valor resultante esté en un rango estándar (generalmente de -1 a 1).\n",
    "   - La fórmula de normalización convierte la cantidad de discordancias en un valor que puede interpretarse como un coeficiente de correlación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 03:27:20,171 - INFO     - Calculando la matriz de correlación Xi...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'xxlimited' has no attribute 'xicor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Calcular la matriz de correlación Xi\u001b[39;00m\n\u001b[0;32m     25\u001b[0m app_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculando la matriz de correlación Xi...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m matriz_xi \u001b[38;5;241m=\u001b[39m \u001b[43mcalcular_matriz_xi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_filtrado\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Visualizar la matriz de correlación\u001b[39;00m\n\u001b[0;32m     29\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m16\u001b[39m))\n",
      "Cell \u001b[1;32mIn[13], line 18\u001b[0m, in \u001b[0;36mcalcular_matriz_xi\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     16\u001b[0m     matriz_xi[i, j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 18\u001b[0m     xi_valor \u001b[38;5;241m=\u001b[39m \u001b[43mxicor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxicor\u001b[49m(df\u001b[38;5;241m.\u001b[39miloc[:, i], df\u001b[38;5;241m.\u001b[39miloc[:, j])\n\u001b[0;32m     19\u001b[0m     matriz_xi[i, j] \u001b[38;5;241m=\u001b[39m xi_valor\n\u001b[0;32m     20\u001b[0m     matriz_xi[j, i] \u001b[38;5;241m=\u001b[39m xi_valor\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'xxlimited' has no attribute 'xicor'"
     ]
    }
   ],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xxlimited as xicor\n",
    "\n",
    "# Función para calcular la matriz de correlación Xi\n",
    "def calcular_matriz_xi(df):\n",
    "    n = df.shape[1]\n",
    "    matriz_xi = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            if i == j:\n",
    "                matriz_xi[i, j] = 1.0\n",
    "            else:\n",
    "                xi_valor = xicor.xicor(df.iloc[:, i], df.iloc[:, j])\n",
    "                matriz_xi[i, j] = xi_valor\n",
    "                matriz_xi[j, i] = xi_valor\n",
    "    \n",
    "    return pd.DataFrame(matriz_xi, index=df.columns, columns=df.columns)\n",
    "\n",
    "# Calcular la matriz de correlación Xi\n",
    "app_logger.info(\"Calculando la matriz de correlación Xi...\")\n",
    "matriz_xi = calcular_matriz_xi(train_data_filtrado)\n",
    "\n",
    "# Visualizar la matriz de correlación\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(matriz_xi, annot=False, cmap='coolwarm', vmin=0, vmax=1)\n",
    "plt.title('Matriz de Correlación Xi')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "app_logger.info(\"Se ha generado la matriz de correlación Xi y se ha visualizado como un mapa de calor.\")\n",
    "\n",
    "# Encontrar las correlaciones más fuertes\n",
    "correlaciones_fuertes = matriz_xi.unstack().sort_values(ascending=False).drop_duplicates()\n",
    "correlaciones_fuertes = correlaciones_fuertes[correlaciones_fuertes < 1.0]  # Excluir autocorrelaciones\n",
    "top_correlaciones = correlaciones_fuertes.head(10)\n",
    "\n",
    "print(\"Top 10 correlaciones más fuertes:\")\n",
    "print(top_correlaciones)\n",
    "app_logger.info(\"Se han identificado las 10 correlaciones más fuertes utilizando el método Xi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Características de porches y terrazas\n",
    "app_logger.info(\"Creando características relacionadas con porches y terrazas...\")\n",
    "\n",
    "# Calcular el área total de porches\n",
    "train_data['TotalPorchArea'] = train_data['OpenPorchSF'] + train_data['EnclosedPorch'] + \\\n",
    "                               train_data['3SsnPorch'] + train_data['ScreenPorch']\n",
    "\n",
    "# Crear indicador binario para casas con porches\n",
    "train_data['HasPorch'] = (train_data['TotalPorchArea'] > 0).astype(int)\n",
    "\n",
    "app_logger.info(\"Se han creado nuevas características: 'TotalPorchArea' y 'HasPorch'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Possible Features\n",
    "- Based on ``YearRemodAdd`` and ``YearBuilt`` as the dataset description stated, if they are equal that means that the house is not remodeled and if its different means that it has been remodeled, we can add a binary feature indicating this.\n",
    "- Reduce ``YearBuilt`` and ``YrSold`` to ``TimeToSell``.\n",
    "- Convert ``YearRemodAdd`` to ``TimeUntilRemod`` that means the time since it was built until it was remod, and ``RemodUntilSale`` that is the time since it was remod until it was sold.\n",
    "- Porch and Deck Areas: Create a total porch area feature and a binary indicator for houses with porches.\n",
    "- Proximity and Neighborhood Effects: Group neighborhoods into clusters based on median house prices to capture locality effects.\n",
    "- GeoCode neighborhoods.\n",
    "- Total Square Footage: Combine all square footage features (``1stFlrSF``, ``2ndFlrSF``, ``TotalBsmtSF``, etc.) into a single feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inconsistencies\n",
    "- In some cases ``GarageYrBlt`` (year that the garage was built) was previous to ``YearBuilt`` which is not logical. We can modify this cases and transform those values to the year that the house was built assumming this criterion. This variable is related mostly with the built year and the Remodelation year that we can discard it as it only adds complexity with no info to the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finrl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
